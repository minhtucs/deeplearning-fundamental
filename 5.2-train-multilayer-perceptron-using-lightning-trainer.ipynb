{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a multilayer Perceptron using Lightning Trainer\n",
    "https://lightning.ai/courses/deep-learning-fundamentals/overview-organizing-your-code-with-pytorch-lightning/5-2-training-a-multilayer-perceptron-using-the-lightning-trainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import dataset, DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./dataset/mnist', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./dataset/mnist', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = dataset.random_split(train_dataset, [55000, 5000])\n",
    "print(f'size of train: {len(train_dataset)} \\nsize of val: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine labels distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_data_loaders(batch_size=64)\n",
    "\n",
    "train_counter = Counter()\n",
    "for batch_features, labels in train_dataloader:\n",
    "    train_counter.update(labels.tolist())\n",
    "\n",
    "print(sorted(train_counter.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_label = train_counter.most_common(1)[0]\n",
    "basline_acc = most_common_label[1] / sum(train_counter.values())\n",
    "print(f'baseline accuracy: {basline_acc*100 :.02f}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchMnistMLP(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        layer1_outputs = 50\n",
    "        layer2_outputs = 25\n",
    "        \n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_features, layer1_outputs),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            torch.nn.Linear(layer1_outputs, layer2_outputs),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            torch.nn.Linear(layer2_outputs, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningMLP(lightning.LightningModule):\n",
    "    def __init__(self, model, learning_rate):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # save hyperparameters (but skip the model parameters)\n",
    "        self.save_hyperparameters(ignore=['model'])\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task='multiclass', num_classes=10) # hardcode?\n",
    "        self.val_acc = torchmetrics.Accuracy(task='multiclass', num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def _process_step(self, batch, batch_idx):\n",
    "        batch_features, batch_labels = batch\n",
    "        logits = self.forward(batch_features)\n",
    "        loss = F.cross_entropy(logits, batch_labels)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        return loss, predictions, batch_labels\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, predictions, labels = self._process_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.train_acc(predictions, labels)\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, predictions, labels = self._process_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.val_acc(predictions, labels)\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, predictions, labels = self._process_step(batch, batch_idx)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.val_acc(predictions, labels)\n",
    "        self.log('test_acc', self.val_acc, prog_bar=True)\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_data_loaders(batch_size=64)\n",
    "\n",
    "pytorch_mnist_model = PytorchMnistMLP(num_features=784, num_classes=10)\n",
    "lightning_model = LightningMLP(pytorch_mnist_model, 0.05)\n",
    "\n",
    "trainer = lightning.Trainer(\n",
    "    max_epochs=10, \n",
    "    accelerator='auto', \n",
    "    devices=1,\n",
    "    deterministic=True)\n",
    "\n",
    "trainer.fit(model=lightning_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "test_acc = trainer.test(dataloaders=test_dataloader)[0]['accuracy']\n",
    "\n",
    "print(f\"\"\"\n",
    "test accuracy: {test_acc}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organize Data Loaders with Data Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataModule(lightning.LightningDataModule):\n",
    "    def __init__(self, data_dir='dataset/mnist', batch_size=64):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        datasets.MNIST(root=self.data_dir, train=True, transform=transforms.ToTensor(), download=True)\n",
    "        datasets.MNIST(root=self.data_dir, train=False, transform=transforms.ToTensor(), download=True)\n",
    "    \n",
    "    # for multi GPUs\n",
    "    def setup(self, stage: str):\n",
    "        self.test_dataset = datasets.MNIST(root=self.data_dir, train=False, transform=transforms.ToTensor(), download=False)\n",
    "        the_train_dataset = datasets.MNIST(root=self.data_dir, train=True, transform=transforms.ToTensor(), download=False)\n",
    "        self.train_dataset, self.val_dataset = dataset.random_split(the_train_dataset, [55000, 5000])\n",
    "        self.predict_dataset = datasets.MNIST(root=self.data_dir, train=False, transform=transforms.ToTensor(), download=False) # ?\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset=self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset=self.val_dataset, batch_size=self.batch_size)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(dataset=self.test_dataset, batch_size=self.batch_size)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(dataset=self.predict_dataset, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_datamodule = MnistDataModule(batch_size=64)\n",
    "model = LightningMLP(PytorchMnistMLP(num_features=784, num_classes=10), 0.05)\n",
    "\n",
    "trainer = lightning.Trainer(\n",
    "    max_epochs=10, \n",
    "    accelerator='auto', \n",
    "    devices=1, \n",
    "    deterministic=True,\n",
    "    logger=CSVLogger(save_dir='lightning_logs', name='csv') # so, not use TensorBoard\n",
    ")\n",
    "\n",
    "trainer.fit(model=model, datamodule=mnist_datamodule)\n",
    "# save the model checkpoint so can load it later\n",
    "trainer.save_checkpoint('checkpoints/mnist_classifier.ckpt')\n",
    "# LightningMLP.load_from_checkpoint('mnist_model.ckpt', model=pytorch_mnist_model)\n",
    "\n",
    "test_acc = trainer.test(datamodule=mnist_datamodule)\n",
    "val_acc = trainer.validate(datamodule=mnist_datamodule)\n",
    "# predict_acc = trainer.predict(datamodule=mnist_datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize metrics from CSV logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n",
    "df_metrics.head()\n",
    "df_metrics_aggr = df_metrics.groupby(['epoch']).mean()\n",
    "\n",
    "df_metrics_aggr[['train_loss', 'val_loss']].plot(grid=True, legend=True, xlabel='Epoch', ylabel='Loss')\n",
    "df_metrics_aggr[['train_acc', 'val_acc']].plot(grid=True, legend=True, xlabel='Epoch', ylabel='Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_mnist_model = PytorchMnistMLP(num_features=784, num_classes=10)\n",
    "lightning_model = LightningMLP.load_from_checkpoint('checkpoints/mnist_classifier.ckpt', model=pytorch_mnist_model)\n",
    "lightning_model # something wrong with the model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
