{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a multilayer Perceptron using Lightning Trainer\n",
    "https://lightning.ai/courses/deep-learning-fundamentals/overview-organizing-your-code-with-pytorch-lightning/5-2-training-a-multilayer-perceptron-using-the-lightning-trainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import dataset, DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./dataset/mnist', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./dataset/mnist', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train: 55000 \n",
      "size of val: 5000\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = dataset.random_split(train_dataset, [55000, 5000])\n",
    "print(f'size of train: {len(train_dataset)} \\nsize of val: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine labels distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5446), (1, 6195), (2, 5479), (3, 5618), (4, 5365), (5, 4941), (6, 5416), (7, 5747), (8, 5363), (9, 5430)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_data_loaders(batch_size=64)\n",
    "\n",
    "train_counter = Counter()\n",
    "for batch_features, labels in train_dataloader:\n",
    "    train_counter.update(labels.tolist())\n",
    "\n",
    "print(sorted(train_counter.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 11.26$\n"
     ]
    }
   ],
   "source": [
    "most_common_label = train_counter.most_common(1)[0]\n",
    "basline_acc = most_common_label[1] / sum(train_counter.values())\n",
    "print(f'baseline accuracy: {basline_acc*100 :.02f}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchMnistMLP(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        layer1_outputs = 50\n",
    "        layer2_outputs = 25\n",
    "        \n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_features, layer1_outputs),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            torch.nn.Linear(layer1_outputs, layer2_outputs),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            torch.nn.Linear(layer2_outputs, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningMLP(lightning.LightningModule):\n",
    "    def __init__(self, model, learning_rate):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task='multiclass', num_classes=10) # hardcode?\n",
    "        self.val_acc = torchmetrics.Accuracy(task='multiclass', num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def _process_step(self, batch, batch_idx):\n",
    "        batch_features, batch_labels = batch\n",
    "        logits = self.forward(batch_features)\n",
    "        loss = F.cross_entropy(logits, batch_labels)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        return loss, predictions, batch_labels\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, predictions, labels = self._process_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.train_acc(predictions, labels)\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, predictions, labels = self._process_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.val_acc(predictions, labels)\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, predictions, labels = self._process_step(batch, batch_idx)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.val_acc(predictions, labels)\n",
    "        self.log('test_acc', self.val_acc, prog_bar=True)\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3944051), started 0:19:49 ago. (Use '!kill 3944051' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-28c528277900fa06\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-28c528277900fa06\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | PytorchMnistMLP    | 40.8 K\n",
      "1 | train_acc | MulticlassAccuracy | 0     \n",
      "2 | val_acc   | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "40.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "40.8 K    Total params\n",
      "0.163     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca334360d50e4a4cb34a8a81cce800e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/.local/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/tu/.local/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930bd79a3c00438b85cee9d70af80fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9243d27da3415c9d9d64b84bb72f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb4cad2cbc14fd59332f5cabc4f024e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327bd5334da34c1da64f6b62080f37dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9235e8e0fe471ebf43219354d3d765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5184240557344a84939a01067d0f64e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce629ef0f169402abd4c93e599252c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e0a89f00d44b6b84c16a2a0b65d5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e555b738d2684ee8b249e9c61ba1cb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a315f64a58ae45f09ac9b7f4fb97a0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875fcc3847a84805a7f82d77528edbf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "/home/tu/.local/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at /media/tu/data/dev/python/deeplearning-fundamental-course/lightning_logs/version_11/checkpoints/epoch=9-step=8600.ckpt\n",
      "Loaded model weights from the checkpoint at /media/tu/data/dev/python/deeplearning-fundamental-course/lightning_logs/version_11/checkpoints/epoch=9-step=8600.ckpt\n",
      "/home/tu/.local/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97d042a43fc4394aed93a3af80ffac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9664999842643738\n",
      "        test_loss           0.11165992170572281\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/tu/dev/python/deeplearning-fundamental-course/5.2-train-multilayer-perceptron-using-lightning-trainer.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tu/dev/python/deeplearning-fundamental-course/5.2-train-multilayer-perceptron-using-lightning-trainer.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m trainer \u001b[39m=\u001b[39m lightning\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, accelerator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, devices\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tu/dev/python/deeplearning-fundamental-course/5.2-train-multilayer-perceptron-using-lightning-trainer.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m trainer\u001b[39m.\u001b[39mfit(model\u001b[39m=\u001b[39mlightning_model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloader, val_dataloaders\u001b[39m=\u001b[39mval_dataloader)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tu/dev/python/deeplearning-fundamental-course/5.2-train-multilayer-perceptron-using-lightning-trainer.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m test_acc \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtest(dataloaders\u001b[39m=\u001b[39;49mtest_dataloader)[\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tu/dev/python/deeplearning-fundamental-course/5.2-train-multilayer-perceptron-using-lightning-trainer.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tu/dev/python/deeplearning-fundamental-course/5.2-train-multilayer-perceptron-using-lightning-trainer.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mtest accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_acc\u001b[39m}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tu/dev/python/deeplearning-fundamental-course/5.2-train-multilayer-perceptron-using-lightning-trainer.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_data_loaders(batch_size=64)\n",
    "\n",
    "pytorch_mnist_model = PytorchMnistMLP(num_features=784, num_classes=10)\n",
    "lightning_model = LightningMLP(pytorch_mnist_model, 0.05)\n",
    "\n",
    "trainer = lightning.Trainer(\n",
    "    max_epochs=10, \n",
    "    accelerator='auto', \n",
    "    devices=1,\n",
    "    deterministic=True)\n",
    "\n",
    "trainer.fit(model=lightning_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "test_acc = trainer.test(dataloaders=test_dataloader)[0]['accuracy']\n",
    "\n",
    "print(f\"\"\"\n",
    "test accuracy: {test_acc}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
