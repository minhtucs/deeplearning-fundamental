{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging Neural Network\n",
    "https://lightning.ai/courses/deep-learning-fundamentals/unit-6-overview-essential-deep-learning-tips-tricks/6.8-debugging-deep-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from common_def import CustomDataModule, CustomDataset, PyTorchMLP\n",
    "import lightning\n",
    "import torchmetrics\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(lightning.LightningModule):\n",
    "    def __init__(self, num_classes=None, num_features=None, hidden_units=None, learning_rate=None):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.torch_model = PyTorchMLP(num_features=num_features, hidden_units=hidden_units, num_classes=num_classes)\n",
    "\n",
    "        # save hyperparameters (but skip the model parameters)\n",
    "        self.save_hyperparameters(ignore=['model'])\n",
    "\n",
    "        # for model summary; 32 is batch_size?\n",
    "        self.example_input_array = torch.Tensor(32, num_features)\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.torch_model(x)\n",
    "    \n",
    "    def _process_step(self, batch, batch_idx):\n",
    "        batch_features, batch_labels = batch\n",
    "        logits = self.forward(batch_features)\n",
    "        loss = F.cross_entropy(logits, batch_labels)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        return loss, predictions, batch_labels\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, predictions, labels = self._process_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.train_acc(predictions, labels)\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, predictions, labels = self._process_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.val_acc(predictions, labels)\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, predictions, labels = self._process_step(batch, batch_idx)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.val_acc(predictions, labels)\n",
    "        self.log('test_acc', self.val_acc, prog_bar=True)\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        # return optimizer # without scheduler\n",
    "\n",
    "        # use Learning Rate scheduler\n",
    "        # for every 10 epochs, reduce the learning rate by a factor of 0.5\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = CustomDataModule()\n",
    "dm.setup(stage='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop early to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 5 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name        | Type               | Params | In sizes  | Out sizes\n",
      "---------------------------------------------------------------------------\n",
      "0 | torch_model | PyTorchMLP    | 6.4 K  | [32, 100] | [32, 2]  \n",
      "1 | train_acc   | MulticlassAccuracy | 0      | ?         | ?        \n",
      "2 | val_acc     | MulticlassAccuracy | 0      | ?         | ?        \n",
      "---------------------------------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc2d9c33b064aed902ed4fae4f79945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8799f708adac40f2a4d404b9485e9901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=5` reached.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12)\n",
    "\n",
    "lightning_model = LightningModel(num_features=100, hidden_units=[50, 25], num_classes=2, learning_rate=0.05)\n",
    "\n",
    "trainer = lightning.Trainer(\n",
    "    max_epochs=10, \n",
    "    fast_dev_run=5, # stop after 5 steps\n",
    "    deterministic=True\n",
    ")\n",
    "\n",
    "trainer.fit(model=lightning_model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name                 | Type               | Params | In sizes  | Out sizes\n",
      "------------------------------------------------------------------------------------\n",
      "0 | torch_model          | PyTorchMLP    | 6.4 K  | [32, 100] | [32, 2]  \n",
      "1 | torch_model.layers   | Sequential         | 6.4 K  | [32, 100] | [32, 2]  \n",
      "2 | torch_model.layers.0 | Linear             | 5.0 K  | [32, 100] | [32, 50] \n",
      "3 | torch_model.layers.1 | ReLU               | 0      | [32, 50]  | [32, 50] \n",
      "4 | torch_model.layers.2 | Linear             | 1.3 K  | [32, 50]  | [32, 25] \n",
      "5 | torch_model.layers.3 | ReLU               | 0      | [32, 25]  | [32, 25] \n",
      "6 | torch_model.layers.4 | Linear             | 52     | [32, 25]  | [32, 2]  \n",
      "7 | train_acc            | MulticlassAccuracy | 0      | ?         | ?        \n",
      "8 | val_acc              | MulticlassAccuracy | 0      | ?         | ?        \n",
      "------------------------------------------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "summary = ModelSummary(lightning_model, max_depth=-1)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
